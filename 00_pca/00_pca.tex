\documentclass[10pt]{ujarticle}

\usepackage{graphicx}
\usepackage[dvipdfmx]{color}
\usepackage[dvipdfmx]{hyperref}
\usepackage{pxjahyper}
\usepackage{subcaption}
\usepackage{here}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{arydshln}

\hypersetup{
setpagesize=false,
 bookmarksnumbered=true,%
 bookmarksopen=true,%
 colorlinks=true,%
 linkcolor=blue,
 citecolor=red,
}

\title{バイオマンでも多様体が知りたい－00\\〜PCAをノリで理解しないことから開始〜}
\author{\href{mailto:yujiokano@keio.jp}{岡野雄士}}
\date{2023/02/20}


\begin{document}
\maketitle
\section{今回の目標}
実は世の中のさまざまなアルゴリズムには数学的構造が背景に潜んでいるが、我々はそれを意識しないでも十分に生活できている。例えば、パソコンで文字を打つという操作の背景には、代数構造が潜んでおり、
パソコンは入力情報を代数構造に従って文字を表示しているのである。しかし、このことを全く意識しなくとも文字を打つことはできる。
それはなぜだろうか？あくまでこれは私見であるが、それは数学的な妥当性が"誰か"によって担保されているからではないだろうか。
我々は誰かが証明した定理や法則を既知のものとして、地道な思索に耽ることを回避し、文明の進化を加速させてきた。

しかし、今日の生物学はどうであろうか。single cell tech.によって、以前に我々が知り得たものよりも圧倒的にリッチな情報を適切に処理することが求められている中で
様々なツールが開発され、そのアルゴリズムの背景を知らなくとも簡単にこのようなデータを処理できてしまう便利な時代となっている。しかし、これらのアルゴリズムの妥当性は誰が証明してくれるのだろうか？
そして何よりも、生物学的な妥当性は誰が確認するのだろうか？生物学的妥当性は決して一意的ではないであろう。線虫の腸管で示された事項がヒトの脳でも自明に事実となるであろうか？
生物学は博物学的に各論を集約してきた歴史があるため、極論としては自分の興味のある対象については自分で吟味するしかないであろう。

ここまでダラダラとポエムめいたことを書いてしまったが、今回の目標は以下の通りである。

\begin{enumerate}
  \item 生物学研究において数学の必要性を感じる
  \item 線形代数・微分積分・確率統計といった分野を身近に感じる
  \item それらの足がかりとして主成分分析（PCA）を数式で理解する
\end{enumerate}

\subsection{注意}
個人的な備忘録と生物学者への説明の練習が主眼なので、無駄な部分は適宜スキップしてください。誤字脱字は適宜修正します。書き殴りなので、常体と敬体がぐちゃぐちゃで読みにくいと思いますが、そこはご愛嬌ということで...

\subsection{ノーテーションについて}
ここでは、今後用いるノーテーションの一部を先に紹介しておく。
なるべく一般的なものを用いるようにするが、一応確認しておいてもらいたい。
$$
\begin{aligned}
  & \mathbb{R}:\text{実数}\qquad\mathbb{N}:\text{自然数}\qquad\forall:\text{任意の}\qquad\exists:\text{ある（存在する）}\\
  & ^\forall x \in \mathbb{R}:\text{実数値をとる任意の変数} x \\
  & p(X=x):\text{確率変数} X \text{の値が} x \text{となる確率}\\
  & ^\exists\mathbf{x}\in\mathbb{R}^n:\text{ある実数} n \text{次元ベクトル}\mathbf{x}\\
  & \text{iff: if and only if}
\end{aligned}
$$

\section{序論：これ、わかりますか？}
\subsection{あれもこれもベクトル}
線形代数というと、ベクトルや行列を扱うことは有名であると思う。私も学部一年で線形代数を学んだ時に単位はもらえたため、それくらいのことは覚えていたが、
正直なところ、当時は線形代数が生物学にどう生きているか全く理解していなかった。しかし、世の中は実にベクトルに溢れていると言える。そして、細胞も「見方によっては」ベクトルであると言える。
ここでは、そのニュアンスを掴んでもらいたい。

実は、ベクトルを扱う上で、それと同時にベクトルの帰属する全体集合であるベクトル空間を考えていることになるのであるが、ベクトル空間とは、以下の定義を満たすものであれば
何でもベクトル空間なのである（厳密な定義はまた別の機会におこなう）。
$$
\begin{aligned}
  \hypertarget{vecsp}{Def)&\quad\text{ベクトル空間} V:}\\
  1.& \text{要素同士の足し算をすることができる}\\
  2.& \text{要素に対してスカラー積（例：実数倍）を行うことができる。}\\
  3.& \text{要素同士の足し算とスカラー積の順番を入れ替えられる}\\
  &\text{例：}^\forall a\in\mathbb{R},^\forall x,y\in V,\; a(\mathbf{x+y})=a\mathbf{x}+a\mathbf{y}\\
  4.& \text{スカラー同士の足し算とスカラー積の順番を入れ替えられる}\\
  &\text{例：}^\forall a,b\in\mathbb{R},^\forall x\in V,\; (a+b)\mathbf{x}=a\mathbf{x}+b\mathbf{x}
\end{aligned}
$$
中でも注目してもらいたいのが、「足し算ができる」という性質と、「スカラー積ができる」という性質であり、これらをまとめて「線形性」と呼ぶ。幾分か当たり前のように見えただろうか。だとすれば、それは自然科学の様々な現象がベクトルを使って表記されているから（すなわち、線形的な数学的構造に依存しているから）であろう。また、ベクトルと聞いた際に、「高校数学で扱った三角形の問題で使ったな」のような、幾何ベクトルのイメージから脱却してもらえただろうか。もちろん、高校の幾何ベクトルもベクトルの一側面であることには間違いないのであるが、幾何ベクトルだけがベクトルなのではなく、線形性があるもののことをベクトルというのである。

さて、先ほど細胞も「見方によっては」ベクトルと言ったが、これはどういうことだろうか。例として、single cell RNA sequencing（scRNA-seq）のデータを考える。
例えば、ある細胞についての$d$個の遺伝子群の転写量が$\log_2(TPM+1)$で与えられているとしよう（$^\forall\mathbf{x}\in\mathbb{R}^d$とする）。
また、別の細胞に対応するデータ$^\forall\mathbf{y}\in\mathbb{R}^d$を考えると、$\mathbf{x+y}$を考えることは何ら不自然ではないであろう。また、何らかの実数$^\forall\alpha\in\mathbb{R}$によってスカラー倍して、$\alpha\mathbf{x}$を考えることも全く自然なことであろう。
実際、全遺伝子について発現量の平均値を計算することに疑問を持たないのであれば、足し算やスカラー積の操作についても前提として許していることになる。
そして、このように線形性をもつため、scRNA-seqデータはベクトルであり、scRNA-seqデータはベクトル空間に存在することになる。

しかし、これは数学上の話であって、生物学的な観点からの妥当性は如何であろうか。すなわち、細胞をベクトルとして表現するモデルは生物学的に妥当なのか？ということである。
そのためには、生物学的な意味と数学的な意味を突き合わせて考える必要がある。しかし、生物学と数学には大きな違いがあり、「生物学では起こりそうなことの性質を議論する」一方で、数学では「どんなに極端な状況でも成立する性質を議論する」ことである。具体的に言うのであれば、細胞の議論をベクトル空間での議論に置き換えることで、対応する細胞が存在し得ないようなベクトルについても許してしまうことになる。生物学的に言えば、細胞と細胞の遺伝子発現量を足した$\mathbf{x+y}$のような状況は細胞の遺伝子発現量といえるのだろうか。
また、$1234.456\mathbf{x}$のようにスカラー倍した状況は細胞の遺伝子発現量と言えるのであろうか。この生物学的な妥当性は「見方によっては」正しいし、逆も然りであろう。

生物学で使われている数学を数式や定義といった、数学で用いられている表記で書き表すことは、その理論の前提や帰結がもつ性質を吟味することにつながるため、我々生物学者はそこに生物学的解釈が伴うか注視する余地が生まれる。
一方で、数学的理論の背景事項に対する厳密性が失われると、生物学的観点との照会が困難となる。
だからこそ、数学は数学のまま語るべきであり、生物学者は数学を用いる前のモデル化のプロセスにも目を光らせるべきではないだろうか。

\subsection{PCAって何ですか？}
あなたは、「PCAって何ですか？」と聞かれた時に一行程度の文章で説明できるであろうか。実際の数式を見る前の自分は、「線形的な次元削減」と認識していたが、これは本質的ではない。
なぜならば、次元削減と対応する部分は、累積寄与率を減らす人為的な操作に付随するものであって、原理上、累積寄与率は100\%まで計算できるし、実際にお使いのライブラリでもそのように
計算しているはずである。

また、「分散が最大になるように第一主成分を取ってきて、それと直交するなかで分散が最大になる第二主成分をとって...」のような説明法もよくされていると思うが、その説明から数式を書き起こせる人がどのくらいいるだろうか。
私も最初にPCAの概念に触れた時にはそのように教わったが、何となくイメージできても数式を想起できなかった。前述のように、数式に書き起こすことは、前提や帰結を注視することに役立つので、なるだけ数式がイメージしやすいような
説明ができるのに越したことはない。

私が用意した回答は、「分散共分散行列の固有値分解と固有ベクトルによる基底変換」である。数式がイメージしやすく、短く纏まっているであろう。
実はこのドキュメントのオチは、PCAが分散共分散行列の固有値分解であることを説明することなので、既知の場合は以下は不要となる。この説明と既出の説明との関連性において少しでも疑問点があれば、
このドキュメントを通じて、\hyperlink{bases_and_dim}{次元}の話や、軸の\hyperlink{innerprod}{直交性}の話、\hyperlink{eigen}{固有値分解}の話などはカバーしていきたいと思うので、お付き合いいただきたい。

\subsection{一次独立と軸の直交性は全くの別物}
一次独立も直交な軸も、お互いに影響がなさそうなイメージがして、同じような議論に思えてしまうであろうか。しかし、これらは全く違う話をしている。RNA-seqデータそのものや、PCAを用いたデータ解析結果の議論において、一次独立性や直交性などのタームは非常に重要であるため、正確に理解していることが非常に重要である。結論から言えば、基底同士は定義より一次独立であるが、それが必ずしも直交している必要はない。斜交座標系が良い例である。

これらの違いがわかりやすい他の例としては、3次元内積空間も挙げられる。3次元内積空間とは、その名の通り、内積が定義された3次元ベクトル空間のことである。直交性は3次元に限らず、内積空間の任意の2つのベクトル$^\forall\mathbf{x,y}$について、$\mathbf{x}\cdot\mathbf{y}=0$（但し、$\mathbf{x}\cdot\mathbf{y}$は$\mathbf{x}$と$\mathbf{y}$の内積）となることで定義される。一方で、一次独立性に関して3次元ベクトル空間では、$\mathbf{x}\times\mathbf{y}\neq0$（但し、$\mathbf{x}\times\mathbf{y}$は$\mathbf{x}$と$\mathbf{y}$の外積）と同値条件であることが知られている。このように、一次独立性と軸の直交性は全く別の話をしているのである。

\section{PCAに必要な線形代数}

\hypertarget{bases_and_dim}{\subsection{一次独立性・基底・次元}}
\subsubsection{一次結合}
ここでは、まず一次結合というタームについて触れておく。ちなみに、一次結合・一次独立・一次従属などのタームを用いていくが、それぞれ線型結合・線型独立・線形従属といっても差し支えない。
結局、線形性とは一次関数のように、足せたり、定数倍できるような概念ということを踏まえれば、一次〇〇といっても線形〇〇といっても同じであることがわかりやすいであろう。

さておき、$^\forall i\in\mathbb{N}$に対して、任意のベクトル空間を$V$として、$^\forall\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_i\in V$を考える
（今後、特に前置きがない場合は$\mathbf{x}$のフォントで書かれたものについては、任意のベクトル空間$V$の元とする）。
これら$\mathbf{x}_1,\cdots,\mathbf{x}_i$の一次結合とは、$^\forall\alpha^1,\alpha^2,\cdots,\alpha^i\in\mathbb{R}$を用いて、$\sum_{k=1}^{i}\alpha^k\mathbf{x}_k$と書くことである。
また、$\mathbf{y}:=\sum_{k=1}^{i}\alpha^k\mathbf{x}_k$の場合、$\mathbf{y}$は$\mathbf{x}_1,\cdots,\mathbf{x}_i$の一次結合であるという。
ちなみに、$\alpha^k$は何らかの$\alpha$の$k$乗という意味ではなく、序数を右肩に書いているだけである。このような表記をとるメリットは$\alpha^{k}$自体は$V$の元ではないことが序数の位置によってもわかり、視認性が良くなることである。

\subsubsection{一次独立・一次従属}
次に一次独立の定義について述べる。ただし、$\mathbf{0}$は零ベクトルを示す。
$$
\begin{aligned}
  Def)& ^\forall\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_i\in V\text{が一次独立}\\
  :\Leftrightarrow & ^\forall\mathbf{y},\mathbf{z}\in V, ^\forall\alpha^1,\alpha^2,\cdots,\alpha^i,\beta^1,\beta^2,\cdots\beta^i\in\mathbb{R},\\
  & \mathbf{y}=\sum_{k=1}^{i}\alpha^k\mathbf{x}_k,\mathbf{z}=\sum_{k=1}^{i}\beta^k\mathbf{x}_k,\mathbf{y}=\mathbf{z}\;\text{iff}\; ^\forall k\in\{1,2,\cdots,i\},\alpha^k=\beta^k\\
  :\Leftrightarrow & \sum_{k=1}^{i}\alpha^k\mathbf{x}_i=\mathbf{0}\;\text{iff}\;\alpha^1=\alpha^2=\cdots=\alpha^i=0
\end{aligned}
$$
なお、一次独立でないベクトルの組のことを一次従属といい、さらに一次独立なベクトルの一次結合で表されるベクトルも一次従属であると表現される。

\subsubsection{次元・基底}
次元とは、一次独立なベクトルの組の構成要素の最大数のことである。基底とは、次元数と同じ数の一次独立なベクトルの組のことを指す。
例えば、$n$次元ベクトル空間では、$^\forall\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_n$のように一次独立な組を考えると、それらは基底となる。
また、基底の取り方は一意ではなく、$^\forall\mathbf{y}_1,\mathbf{y}_2,\cdots,\mathbf{y}_n$のように基底を取っても良い。
しかし、$^\forall\mathbf{z}_1,\mathbf{z}_2,\cdots,\mathbf{z}_n,\mathbf{z}_{n+1}$のようにベクトルの組を考えると、次元数は$n$であるため一次従属となるので、これらは基底ではない。
一方で、無限次元ベクトル空間の場合には、有限であればいくらでも多くのベクトルの組を基底として考えることができる。

\hypertarget{innerprod}{\subsection{内積と直交性}}
\subsubsection{内積とノルム}
高校で幾何ベクトルを習った際には、ベクトルと内積はセットで習ったが、\hyperlink{vecsp}{ベクトル空間の定義}に内積は必要ないし、自然に導出もされない。
しかし、高校で扱ったベクトルや一般教養でやった線形代数で内積が使えたのは、計量空間というベクトル空間に内積を導入した特別な空間を扱っていたからであり、それは計量空間の方が性質が良いからである。
ここで内積の定義を確認すると以下の通りである。
$$
\begin{aligned}
  Def)&\text{内積}(\_\cdot\_):V\times V\rightarrow\mathbb{R}\;\text{s.t.}\;^\forall\mathbf{x},\mathbf{y},\mathbf{z}\in V\\
  1.&\mathbf{x}\cdot\mathbf{x}\geq 0\\
  2.&\mathbf{x}\cdot\mathbf{x}=0\;\text{iff}\;\mathbf{x}=\mathbf{0}\\
  3.&^\forall\alpha,\beta\in\mathbb{R},(\alpha\mathbf{x}+\beta\mathbf{y}\cdot\mathbf{z})=\alpha(\mathbf{x}\cdot\mathbf{z})+\beta(\mathbf{y}\cdot\mathbf{z})\\
  4.&\mathbf{x}\cdot\mathbf{y}=\mathbf{y}\cdot\mathbf{x}
\end{aligned}
$$
定義の通り、内積は2つのベクトルを受け取り、実数値を返す写像であり、特別な性質はいくつか要求しているものの幾分か抽象的な概念である。
しかし、以下のようなベクトルを受け取り実数値を返すことでベクトルに"大きさ"の概念を与えることのできる、ノルムというこれまた抽象的な概念を定義すると、
内積とノルムの不思議な関連性が見えてくる。
$$
\begin{aligned}
  Def)&\text{ノルム}\|\_\|:V\rightarrow\mathbb{R}\;\text{s.t.}\;^\forall\mathbf{x},\mathbf{y}\in V,^\forall\alpha\in\mathbb{R}\\
  1.&\|\mathbf{x}\|=0\;\text{iff}\;\mathbf{x}=\mathbf{0}\\
  2.&\|\alpha\mathbf{x}\|=|\alpha|\|\mathbf{x}\|\\
  3.&\|\mathbf{x}+\mathbf{y}\|=\|\mathbf{x}\|+\|\mathbf{y}\|
\end{aligned}
$$

\subsubsection{Caucy-Schwartzの不等式と$L^2$ノルム}
ここまで内積とノルムの定義を確認したが、どちらも抽象的な定義であり、実際に内積もノルムもいくつもの構成方法が存在する。
しかし、内積によってノルムを構成することで、定義にありありとした意味が宿るようになるのである。この、内積とノルムをつなぐ式が以下のCaucy-Schwartzの不等式である（証明はまた別の機会に行う）。
$$
\begin{aligned}
  Theorem)&\text{Caucy-Schwartzの不等式}\\
  &^\forall\mathbf{x},\mathbf{y}\in V,(\mathbf{x}\cdot\mathbf{y})^2\leq\mathbf{x}\cdot\mathbf{x}+\mathbf{y}\cdot\mathbf{y}\\
\end{aligned}
$$
Caucy-Schwartzの不等式を用いることで、$\sqrt{\mathbf{x}}$

\subsubsection{角度・直交性}

\subsubsection{正規直交基底と$n$次元ユークリッド空間}
ここまでは実は$n$次元ユークリッド空間を説明するための準備段階であったが、最後に正規直交基底の定義を紹介する。
ただし、$^\forall V:\text{計量空間},dimV=:n\in\mathbb{N},\{\mathbf{e}_1,\mathbf{e}_2,\cdots,\mathbf{e}_n\}:V\text{の基底}$とする。
$$
\begin{aligned}
  Def)&\text{正規直交基底}\{\mathbf{e}_1,\mathbf{e}_2,\cdots,\mathbf{e}_n\}:\\
  1.&^\forall i\in\{1,2,\cdots,n\},\|\mathbf{e}_i\|=1\\
  2.&^\forall i,j\in\{1,2,\cdots,n\},\mathbf{e}_i\cdot\mathbf{e}_j=0\;\text{iif}\;i\neq j
\end{aligned}
$$
ここまで道具が揃うことでようやく、以下のように、$n$次元ユークリッド空間を定義することができる。
$$
\begin{aligned}
  Def)&n\text{次元ユークリッド空間}V:\\
  1.&dimV=n\in\mathbb{N}\\
  2.&\{\mathbf{e}_i|^\forall i\in\{1,2,\cdots,n\},\mathbf{e}_i\in V\}:\text{正規直交基底}\\
  3.&^\forall\mathbf{x},\mathbf{y}\in V, \mathbf{x}:=\sum_{i=1}^nx^i\mathbf{e}_i,\mathbf{y}:=\sum_{i=1}^ny^i\mathbf{e}_i(^\forall x^i,y^i\in\mathbb{R}),\\
  &\mathbf{x}\cdot\mathbf{y}:=\sum_{i=1}^nx^iy^i
\end{aligned}
$$

\subsection{基底変換行列}
\subsubsection{導入：「基底による表記」と「座標系による表記」}
例えば、$\mathbb{R}^2$に関して、基底をなす（お互いに一次独立な）$^\forall\mathbf{x,y}$を考える。
このとき、$^\forall\alpha,\beta\in\mathbb{R}$に関して、$\alpha\mathbf{x}+\beta\mathbf{y}=:\mathbf{z}$となるようなベクトル$\mathbf{z}$に関して、今後以下の2通りの表記を行うこととする。特に、2つ目の「座標系による表記については、基底を対応する係数が書かれる括弧内での位置によって表しているため、基底の表記を拝借して$xy$座標系と呼ぶことにする。
$$
\begin{aligned}
  1.\;\text{基底による表記：}&\alpha\mathbf{x}+\beta\mathbf{y}\\
  2.\;\text{座標系による表記：}&\begin{pmatrix}\alpha&\beta\end{pmatrix}\;\text{または}\;(\alpha,\beta)
\end{aligned}
$$
座標系（ないしは成分）での表示の際には、横ベクトルで書くことで、縦ベクトルで表記された基底のベクトルとの行列積で、
$\begin{pmatrix}\alpha&\beta\end{pmatrix}\begin{pmatrix}\mathbf{x}\\\mathbf{y}\end{pmatrix}=\alpha\mathbf{x}+\beta\mathbf{y}$
のように基底による表記との整合性を取れるようにする。また、データセットのように複数の点を行列として表す際には、縦方向に伸ばすことでデータ数を表すことにする。
そのため、データ数が$n$で$d$次元のデータは、$n\times d$行列として表現することにする。

\subsubsection{正方行列と基底変換}
正方行列とは、$n\times n$行列のように、行数と列数が同じ行列のことを指す。正方行列はベクトルとの行列積によって、基底の変換を意味するという性質がある。

例えば、$\mathbb{R}^2$に関して、基底をなす（お互いに一次独立な）$^\forall\mathbf{x,y}$をそれぞれ以下のように変換して、新たに基底をなす$\mathbf{u,v}$に対して座標系を変換することを考える。
$$
\begin{aligned}
  \mathbf{u}:=2\mathbf{x}\\
  \mathbf{v}:=\frac{\mathbf{y}}{3}\\
\end{aligned}
$$
このとき、行列$A:=(\begin{smallmatrix}2&0\\0&\frac{1}{3}\end{smallmatrix})$と定義すると、これは以下のように基底を成分にもつベクトルとの行列積によって、基底を変換できていることがわかる。
$$
\begin{aligned}
  \begin{pmatrix}
    \mathbf{u}\\\mathbf{v}
  \end{pmatrix}=A\begin{pmatrix}
    \mathbf{x}\\
    \mathbf{y}
  \end{pmatrix}
\end{aligned}
$$

次に、行列の成分表示によって、$xy$座標系が$uv$座標系に移される過程を考える。例として、$xy$座標が$(\alpha, \beta)$のベクトルの$uv$座標系での座標系$(\alpha^*, \beta^*)$として、これらの値を考えると、
$\mathbf{u}=\frac{1}{2}\mathbf{x}$かつ$\mathbf{v}=3\mathbf{y}$なので、$\alpha\mathbf{x}+\beta\mathbf{y}=\frac{\alpha}{2}\mathbf{u}+3\beta\mathbf{v}$となるため、
$uv$座標は$(\alpha^*, \beta^*)=(\frac{\alpha}{2}, 3\beta)$となる。
そのため、$A$の逆行列である、$A^{-1}=(\begin{smallmatrix}\frac{1}{2}&0\\0&3\end{smallmatrix})$
を用いると、以下のように書き表すことができる。
$$
\begin{aligned}
  \begin{pmatrix}
    \alpha^* & \beta^*
  \end{pmatrix}=\begin{pmatrix}
    \alpha & \beta
  \end{pmatrix}A^{-1}
\end{aligned}
$$
基底そのものと座標の値は反変的であるため、多少分かりにくい点もあるが、$A^{-1}$を$xy$座標系から$uv$座標系への変換行列と捉えると、
成分表示した場合でも、正方行列との行列積によって基底が変換されるということが幾分かわかりやすくなるであろう。


\subsection{行列式}
行列式とは、正方行列に対して定義される指標である。一般には、行数及び列数を置換（並び替え）したときの符号と対応する成分の相乗の総和であるが、
ここではより実用的な計算方法のみ扱う。

\subsubsection{2次の正方行列の場合}
2次の正方行列（$^\forall A:=(\begin{smallmatrix}a&b\\c&d\end{smallmatrix})$）に対して行列式$detA$は以下のように定義される
$$
\begin{aligned}
  detA=\begin{vmatrix} a & b\\ c & d \end{vmatrix}=ad-bc
\end{aligned}
$$
\subsubsection{余因子展開}
まずは、一般化された方法を述べる。$^\forall n,i,j\in\mathbb{N},n\geq i,j,3$とし、任意の$n\times n$行列を$A$とする。
また、$A$の$i$行$j$列成分を$a_{ij}$、$A$から$i$行目及び$j$列目を抜粋してできる$(n-1)\times(n-1)$行列を$\overline{A_{ij}}$と表記することにする。このとき以下が成立する。
$$
\begin{aligned}
  detA=\sum_{k=1}^{n}(-1)^{i+k}a_{ik}\cdot det\overline{A_{ik}}
\end{aligned}
$$

$A=(a_{ij})_{i,j\in\{1,2,3\}}$として、1行目で展開した時の例は以下の通り.
$$
\begin{aligned}
  detA&=det\left(\begin{array}{c:c:c}
    a_{11}&a_{12}&a_{13}\\ \hline
    a_{21}&a_{22}&a_{23}\\
    a_{31}&a_{32}&a_{33}
  \end{array}\right)\\
  &=(-1)^{(1+1)}a_{11}\begin{vmatrix}
    a_{22}&a_{23}\\
    a_{32}&a_{33}
  \end{vmatrix}+(-1)^{(1+2)}a_{12}\begin{vmatrix}
    a_{21}&a_{23}\\
    a_{31}&a_{33}
  \end{vmatrix}+(-1)^{(1+3)}a_{13}\begin{vmatrix}
    a_{21}&a_{22}\\
    a_{31}&a_{32}
  \end{vmatrix}\\
  &=a_{11}(a_{21}a_{33}-a_{23}a_{32})-a_{12}(a_{21}a_{33}-a_{23}a_{31})+a_{13}(a_{21}a_{32}-a_{22}a_{31})\\
  &=a_{11}a_{22}a_{33}-a_{11}a_{23}a_{32}-a_{12}a_{21}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}-a_{13}a_{22}a_{31}
\end{aligned}
$$
$n\geq 4$の場合についても、余因子展開を入れ子にして$2\times 2$行列まで小さくすることで行列式を計算することができる。

\subsubsection{サラスの公式}
特に、$4\times 4$正方行列以上の行列式を求める際に、$3\times 3$正方行列の余因子展開の結果を公式として
用いると計算が楽になる。
$$
\begin{aligned}
  detA=\begin{vmatrix}
    a_{11} & a_{12} & a_{13}\\
    a_{21} & a_{22} & a_{23}\\
    a_{31} & a_{32} & a_{33}
  \end{vmatrix}&=a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}\\
  &-a_{11}a_{23}a_{32}-a_{13}a_{22}a_{31}-a_{12}a_{21}a_{33}
\end{aligned}
$$

図示して覚える方法が有名であるが、個人的には、行数を固定して考えて、$a_{11}a_{22}a_{33}$から$a_{1i}a_{2j}a_{3k}$を作るためには、
何回列数をスワップすればいいかを考え、一回のスワップで$a_{1i}a_{2j}a_{3k}$となる場合はマイナス、二回スワップが必要な場合はプラスという覚え方が
間違えにくいと思う。実際に、奇数回のスワップを奇置換といい負の符号を割り当て、偶数回のスワップを偶置換といい正の符号を割り当てるのが行列式の定義で行なっていることである。

\subsubsection{例題}
末尾に\hyperlink{q1}{解答解説}を用意したので適宜確認されたい。
\begin{enumerate}
  \item $\begin{vmatrix} cos\theta & -sin\theta\\ sin\theta & cos\theta \end{vmatrix}$
  \item $\begin{vmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 2 & 1 & 1 \end{vmatrix}$
  \item $\begin{vmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 3 & 5 & 4 \end{vmatrix}$
  \item $\begin{vmatrix} 1 & 1 & 3 \\ 1 & 2 & 5 \\ 2 & 0 & 2 \end{vmatrix}$
  \item $\begin{vmatrix} 1 & 1 & 0 & 0 \\ 1 & 2 & 3 & 4 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1\end{vmatrix}$
\end{enumerate}
\subsubsection{基底変換行列の行列式}
基底変換行列の行列式は、変換による基底の向きの変化や、変換による基底の伸縮など、幾何学的に重要な様々な情報の尺度である。また、行列式が0となる変換行列は、逆変換に対応する逆行列がないため、変換行列による座標系の変換は点と点の1対1対応関係がないことを意味している。

\hypertarget{eigen}{\subsection{固有値分解}}
\subsubsection{固有値・固有ベクトルの幾何的な意味}
固有値・固有ベクトルとは基底変換に紐づいた概念である。任意の正方行列による変換行列$A$があり、その変換行列で零ベクトルでない、ある特殊なベクトル$\mathbf{x}$を線形変換すると、
変換前のベクトル$\mathbf{x}$と変換後のベクトル$A\mathbf{x}$に関してちょうどある実数$\lambda$によってスカラー倍したとき等しくなるような、特殊な関係（$A\mathbf{x}=\lambda\mathbf{x}$）が成立しているとする。
このとき、$A$による変換は$\mathbf{x}$の方向に関して、$\lambda$倍拡大させる変換と捉えることができる。

この$\mathbf{x}$のような性質をもつベクトルを固有ベクトルといい、$\mathbf{x}$に対する$\lambda$のようなスカラーのことを固有値という。
そのため、固有値は固有ベクトル方向への"空間の拡大率"のように捉えることができる。

\subsubsection{固有値分解の計算方法}
固有値・固有ベクトルの定義から出発する。$^\forall n\in\mathbb{N}$、$A$を任意の$n\times n$正方行列、$I$を$n\times n$単位行列としたとき、次を満たす$^\exists\mathbf{x}\in V(dimV=n),\mathbf{x}\neq\mathbf{0},^\exists\lambda\in\mathbb{R}$について
$$
\begin{aligned}
  A\mathbf{x}=\lambda\mathbf{x}\Leftrightarrow(A-\lambda I)\mathbf{x}=\mathbf{0}
\end{aligned}
$$
ここで、$\mathbf{x}\neq\mathbf{0}$の条件に注目して、仮に$det(A-\lambda I)\neq0$として逆行列$(A-\lambda I)^{-1}$の存在を認めてしまうと、
両辺に左から$(A-\lambda I)^{-1}$をかけると$\mathbf{x}=\mathbf{0}$となり矛盾してしまう。
$$
\begin{aligned}
  \therefore det(A-\lambda I)=0
\end{aligned}
$$
これを固有方程式といい、これを解くと固有値$\lambda$を求めることができる。固有方程式は$\lambda$についての$n$次方程式となるため、重複を含めて$n$個の解が存在する。
固有値が分かれば$A-\lambda I$が定数行列となるため、$(A-\lambda I)\mathbf{x}=\mathbf{0}$を実現する$\mathbf{x}$を何か一つでも見つければそれが固有ベクトルとなる。
$(A-\lambda I)\mathbf{x}=\mathbf{0}$が不定問題であることや、固有ベクトルの定義から、固有ベクトルを定数倍したベクトルもまた固有ベクトルであることから、固有ベクトルは一意的でない。
そのため、仮に$\tilde{\mathbf{x}}$を固有ベクトルの一つとして見つけたとすると、「$k\tilde{\mathbf{x}}(^\forall k\in\mathbb{R})$」のような表記が差し支えない。
また、固有値の数だけ固有ベクトルが存在するため全て算出する必要がある。
\subsubsection{例題}
末尾に\hyperlink{q2}{解答解説}を用意したので適宜確認されたい。
\begin{enumerate}
  \item $\begin{pmatrix}1&3\\-1&5\end{pmatrix}$の固有値と対応する固有ベクトルを求めよ
  \item $\begin{pmatrix}1&0&0\\1&2&4\\5&0&3\end{pmatrix}$の固有値と対応する固有ベクトルを求めよ
\end{enumerate}

\subsubsection{半正定値行列と固有値}
ここで、半正定値行列を紹介する。定義は以下の通りである。
$$
\begin{aligned}
  Def)&^\forall A:n\times n\text{実対称行列が半正定値}(^\forall n\in\mathbb{N})\\
  :\Leftrightarrow&^\forall \mathbf{x}\in\mathbb{R}^n,\mathbf{x}\neq\mathbf{0}\;\text{s.t.}\; A\mathbf{x}\cdot\mathbf{x}\geq0\\
  :\Leftrightarrow&^\forall\lambda:A\text{の固有値}\;\text{s.t.}\;\lambda\geq 0
\end{aligned}
$$
半正定値行列の直接的な定義は内積を用いた定義であるが、同値条件として任意の固有値が非負ものがあり、これは重要な性質である。

\section{PCAに必要な確率統計}
分散共分散行列の定義までさらっと触れられれば十分なので、確率論などの込み入った話は置いておいて、ごくごく簡単に紹介する。

\subsection{一変量の分散}
一変数の確率変数の分散$var(X)$は$X$の期待値$E[X]$を用いて以下のように定義される。
$$
\begin{aligned}
  var(X):=E[(X-E[X])^2]=E[X^2]-(E[X])^2
\end{aligned}
$$
また一般に、確率変数$X$について、標本平均を$\bar{X}$とすると、
$E[\bar{X}]=E[X]$となるため、標本平均は確率変数の期待値の推定量として用いられる。
一方で、標本分散を$S^2$とすると、$S^2:=\overline{(X-\bar{X})^2}=\overline{X^2}-(\bar{X})^2$であるが、
標本数が$^\forall k\in\mathbb{N}$のとき、$E[S^2]=\frac{k-1}{k}var(X)$となる。そのため、不偏分散$U^2:=\frac{k}{k-1}S^2$が
確率変数の分散の推定量として用いられる。

\subsection{多変量の分散共分散行列}
多変量の分散共分散行列の例として、$^\forall n\in\mathbb{N}$について、$X_1,X_2,\cdots,X_n$の$n$変量に関する分散共分散行列$\Sigma$は以下のように定義される
$$
\begin{aligned}
  \Sigma:=\begin{pmatrix}\sigma_{11}&\sigma_{12}&\cdots&\sigma_{1n}\\\sigma_{21}&\sigma_{22}&\cdots&\sigma_{2n}\\\vdots&\vdots&\ddots&\vdots\\\sigma_{n1}&\sigma_{n2}&\cdots&\sigma_{nn}\end{pmatrix}
\end{aligned}
$$
このとき、$^\forall i,j\in\{1,2,\cdots,n\}$に関する$\sigma_{ij}$は以下のように定義される。
$$
\begin{aligned}
  \sigma_{ij}:=E[(X_i-E[X_i])(X_j-E[X_j])]
\end{aligned}
$$
この定義は、各成分が分散または共分散に一致するため、$\Sigma$は分散共分散行列とよばれる。また、$\mathbf{X}:=(X_1,X_2,\cdots,X_n)^\top$のようなベクトルを用いれば、
$\Sigma$は以下のように書き表すことができ、一変量の分散を自然に多変量に拡張したことがわかる。
$$
\begin{aligned}
  \Sigma=E[(\mathbf{X}-E[\mathbf{X}])(\mathbf{X}-E[\mathbf{X}])^\top]
\end{aligned}
$$
ちなみに、$\Sigma$は半正定値行列であり、$^\forall \mathbf{x}\in\mathbb{R}^d,\mathbf{x}\neq\mathbf{0}$を確率変数でない任意のベクトルとして、$\Sigma\mathbf{x}$と$\mathbf{x}$の内積を求めると、以下のように常に非負となる。
$$
\begin{aligned}
  \Sigma\mathbf{x}\cdot\mathbf{x}&=\mathbf{x}^\top\Sigma\mathbf{x}=\mathbf{x}^\top E[(\mathbf{X}-E[\mathbf{X}])(\mathbf{X}-E[\mathbf{X}])^\top]\mathbf{x}\\
  &=E[\mathbf{x}^\top (\mathbf{X}-E[\mathbf{X}])(\mathbf{X}-E[\mathbf{X}])^\top \mathbf{x}]\\
  &=E[(\mathbf{x}\cdot(\mathbf{X}-E[\mathbf{X}]))((\mathbf{X}-E[\mathbf{X}])\cdot\mathbf{x})]\\
  &=E[(\mathbf{x}\cdot(\mathbf{X}-E[\mathbf{X}]))^2]\geq 0
\end{aligned}
$$
すなわち、$\Sigma$の固有値は全て非負となる。

\section{PCAについて}
$^\forall n,d\in\mathbb{N},n\geq d$のとき、$n\times d$行列であるデータセットに対応する、確率変数$X_1,X_2,\cdots X_d$の分散共分散行列で$d\times d$行列の$\Sigma$を考える。
このとき、データから真の$E[X_i]$（$^\forall i\in\{1,2,\cdots, d\}$）を求めることができないため、代わりに推定量である$\overline{X_i}$を用いることになる。このとき、標本分散的に$\Sigma$を計算しても、
不偏分散のように計算しても、結局$\frac{n-1}{n}$倍のスカラー倍がかかるかかからないかの問題なので、PCAをする上では理論上影響しない。
\subsection{主成分スコア・寄与率}
\subsection{軸の直交性について}
固有値分解の重要な性質として、任意の実対称行列$^\forall A\in\mathbb{R}^d$の固有ベクトルは正規直交基底となることが挙げられる。
さらに言えば、固有ベクトルを並べた行列を$P$とすると、$P$は必ず直交行列となる。

今回、固有値分解の対象となった$\Sigma$は定義より、実対称行列であるため、固有ベクトルは
\subsection{固有ベクトルによる基底変換}
\subsection{補足1：なぜ最大の分散をとる操作が固有値分解になるのか？}
ラグランジュの未定定数法
\subsection{補足2：実用上の注意事項}
\subsubsection{$n\times d$ vs $d\times n$}
\subsubsection{データリスケーリング}
\subsubsection{$n<d$の場合}


\section{例題の解答・解説}
\hypertarget{q1}{\subsection{行列式}}
\begin{enumerate}
  \item $\begin{vmatrix} cos\theta & -sin\theta\\ sin\theta & cos\theta \end{vmatrix}=cos^2\theta +sin^2\theta=1$
  \item $\begin{vmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 2 & 1 & 1 \end{vmatrix}=1\cdot 2\cdot 1+1\cdot 1\cdot 2+2\cdot 1\cdot 1-1\cdot 1\cdot 1-2\cdot 2\cdot 2-1\cdot 1\cdot 1=-4$
  \item $\begin{vmatrix} 1 & 1 & 2 \\ 1 & 2 & 1 \\ 3 & 5 & 4 \end{vmatrix}=1\cdot 2\cdot 4+1\cdot 1\cdot 3+2\cdot 1\cdot 5-1\cdot 1\cdot 5-2\cdot 2\cdot 3-1\cdot 1\cdot 4=0$
  \item $\begin{vmatrix} 1 & 1 & 3 \\ 1 & 2 & 5 \\ 2 & 0 & 2 \end{vmatrix}=1\cdot 2\cdot 2+1\cdot 5\cdot 2+3\cdot 1\cdot 0-1\cdot 5\cdot 0-3\cdot 2\cdot 2-1\cdot 1\cdot 2=0$
  \item $\begin{vmatrix} 1 & 1 & 0 & 0 \\ 1 & 2 & 3 & 4 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1\end{vmatrix}=-1\cdot1\cdot1+1\cdot2\cdot1-1\cdot3\cdot0+1\cdot4\cdot0=1$
\end{enumerate}
\subsubsection{補足：一次従属性と行列式}
3.と4.の行列式は0となったが、3.は行基本変形、4.は列基本変形をするとそれぞれ3行目と3列目の成分を全て0にすることが可能なことにお気づきだろうか。
このような行列については、それぞれ行または列が一次従属な関係になっているのである。
3.を例にとって、以下のように各行を何らかのベクトルとして表現するように書き換えてみると一次従属であることがわかりやすい。
$$
\begin{aligned}
  \begin{pmatrix}
    \mathbf{a}\\\mathbf{b}\\\mathbf{c}
  \end{pmatrix}=\begin{pmatrix}
    1 & 1 & 2\\
    1 & 2 & 1\\
    3 & 5 & 4
  \end{pmatrix}\begin{pmatrix}
    \mathbf{x}\\\mathbf{y}\\\mathbf{z}
  \end{pmatrix}=\begin{pmatrix}
      \mathbf{x}+\mathbf{y}+2\mathbf{z}\\
      \mathbf{x}+2\mathbf{y}+\mathbf{z}\\
      3\mathbf{x}+5\mathbf{y}+4\mathbf{z}
    \end{pmatrix}=\begin{pmatrix}
      \mathbf{a}\\\mathbf{b}\\\mathbf{a}+2\mathbf{b}
    \end{pmatrix}
\end{aligned}
$$
この場合、仮に$\mathbf{x},\mathbf{y},\mathbf{z}$が基底であっても、
行列式が0となる変換行列をかけると、基底の数が減ってしまうのである。
実際に$\mathbf{a},\mathbf{b}$は基底であっても$\mathbf{c}$はこれらの一次結合で表せるため、基底ではない。
このように、$^\forall n,m\in\mathbb{N},n>m$のとき$n\times n$行列に対して一次独立な行ないしは列が$m$個しかない状態をランク落ちという。

なお、5.については二行目で余因子展開をした結果、1,2列目を除いた場合は単位行列（行列式は1）となり、3,4列目を除いた場合はランク落ちしているため行列式が0となることを利用した
（行基本変形によって$4\times4$単位行列を作ることができるのは明らか）。

\hypertarget{q2}{\subsection{固有値分解}}
\begin{enumerate}
  \item $\lambda=4$のとき$s\begin{pmatrix}1\\1\end{pmatrix}$、$\lambda=2$のとき$t\begin{pmatrix}3\\1\end{pmatrix}$（$^\forall s,t\in\mathbb{R}$）
  \item $\lambda=1$のとき$s\begin{pmatrix}2\\18\\-5\end{pmatrix}$、$\lambda=2$のとき$t\begin{pmatrix}0\\1\\0\end{pmatrix}$、$\lambda=3$のとき$u\begin{pmatrix}0\\4\\1\end{pmatrix}$（$^\forall s,t,u\in\mathbb{R}$）
\end{enumerate}
\subsubsection{補足：ある文字に関する情報が消えている不定問題}
2.の$\lambda=2$の際に固有ベクトルを求めようとすると、$^\forall(p,q,r)^\top\in\mathbb{R}^3$として、以下の連立方程式を解くことになる。
$$
\begin{aligned}
  \begin{pmatrix}
    -1&0&0\\1&0&4\\5&0&1
  \end{pmatrix}\begin{pmatrix}
    p\\q\\r
  \end{pmatrix}=\begin{pmatrix}
    -p\\p+qz\\5p+q
  \end{pmatrix}=\mathbf{0}
\end{aligned}
$$
これを解くと、$p=q=0$となるが、$r$に関する情報がない。このような場合は、$r$は任意の実数値を取っても差し支えないと判断できる。
\end{document}
